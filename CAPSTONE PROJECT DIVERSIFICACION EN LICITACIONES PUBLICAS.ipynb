{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98d5cf1",
   "metadata": {},
   "source": [
    "## 1. Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99868c1b-0978-4414-ad4d-0b16de56ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import random\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from rapidfuzz import fuzz, process #limpieza datos\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "import unidecode\n",
    "def remove_accents(a):\n",
    "    return unidecode.unidecode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e556d",
   "metadata": {},
   "source": [
    "##  2. Carga y Procesamiento de Datos\n",
    "\n",
    "En este proceso, se cargaran bases de licitaciones públicas en Chile entre los años 2014-2018.Para esto, se utilizará las licitaciones, la base de sectores para identificar a que sector pertenece la empresa (municipalidad, salud, etc) y por último la base de rubros que nos dará más información sobre la categoría del producto.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04cc00",
   "metadata": {},
   "source": [
    "### 2.1 Cargar licitaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625508aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta donde se encuentran los archivos de licitaciones\n",
    "path = 'C:/Users/SCL_SERVIDOR/Desktop/Capstone Project'  # Cambia esto si tus archivos están en otra carpeta\n",
    "\n",
    "# Definir el patrón de archivos\n",
    "pattern = 'licitaciones_*.csv'\n",
    "\n",
    "# Usar glob para obtener la lista de archivos que coinciden con el patrón\n",
    "all_files = glob.glob(os.path.join(path, pattern))\n",
    "\n",
    "# Verificar los archivos encontrados\n",
    "print(f\"Archivos encontrados: {all_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa34879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar cada DataFrame anual\n",
    "list_of_dfs = []\n",
    "\n",
    "for file in all_files:\n",
    "    # Extraer el año del nombre del archivo\n",
    "    basename = os.path.basename(file)  # Ejemplo: 'licitaciones_2014.csv'\n",
    "    year = basename.split('_')[1].split('.')[0]\n",
    "    \n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(file, sep=',', encoding='latin-1', decimal='.')\n",
    "    \n",
    "    # Añadir una columna para el año\n",
    "    df['Año'] = int(year)\n",
    "    \n",
    "    # Agregar el DataFrame a la lista\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "lic_all_years = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "# Verificar la concatenación\n",
    "print(f\"Total de registros combinados: {lic_all_years.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca512b22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2 Fusión con sectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:/Users/chaco/OneDrive/Escritorio/Magister Data Science/Capstone Proyect/Cod'\n",
    "archivos_en_ruta=os.listdir(ruta)\n",
    "print(archivos_en_ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909c9d2-07d4-4580-9f77-14a98b9116bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo=os.path.join(ruta,'sectores.csv')\n",
    "try:\n",
    "    sectores=pd.read_csv(archivo,sep=\";\")\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo '{archivo}'no se encuentra\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e09631-3de5-4766-bd1a-00366d19cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que las columnas clave están en el mismo formato\n",
    "lic_all_years['NombreOrganismo'] = lic_all_years['NombreOrganismo'].astype(str).str.strip()\n",
    "sectores['Nombre de la institución'] = sectores['Nombre de la institución'].astype(str).str.strip()\n",
    "\n",
    "# Fusionar con sector \n",
    "lic_all_years = pd.merge(\n",
    "    lic_all_years,\n",
    "    sectores[['Nombre de la institución','Sector']],\n",
    "    how='left',\n",
    "    left_on=\"NombreOrganismo\",\n",
    "    right_on='Nombre de la institución'\n",
    ")\n",
    "\n",
    "lic_all_years.drop(columns=[\"Nombre de la institución\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440e955",
   "metadata": {},
   "source": [
    "### 2.3 Fusión con Rubros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b3bff-e122-493c-b063-2ad72a0fad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo=os.path.join(ruta,'rubros_onu.xlsx')\n",
    "try:\n",
    "    rubros_onu=pd.read_excel(archivo)\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo '{archivo}'no se encuentra\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que las columnas clave están en el mismo formato\n",
    "lic_all_years['CodigoProductoONU'] = lic_all_years['CodigoProductoONU'].astype(str).str.strip()\n",
    "rubros_onu['CodigoProductoONU'] = rubros_onu['CodigoProductoONU'].astype(str).str.strip()\n",
    "\n",
    "# Fusionar con rubros ONU\n",
    "lic_all_years = pd.merge(\n",
    "    lic_all_years,\n",
    "    rubros_onu[['CodigoProductoONU','NombreProducto','RubroN2']],\n",
    "    how='left',\n",
    "    on='CodigoProductoONU'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9cd4c4-3fc4-44e7-8170-a99061e95010",
   "metadata": {},
   "source": [
    "### 2.4 Guardar y Cargar Data Unificada (2014-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4970cde-35b8-436d-a5dc-fb9855bedfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta = 'C:/Users/SCL_SERVIDOR/Desktop/Capstone Project/lic_combinadas_2014_2018.csv'\n",
    "#lic_all_years.to_csv(ruta, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528d91a-6f57-422d-b1f0-270fb1eea336",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_all_years = pd.read_csv('lic_combinadas_2014_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da614a07",
   "metadata": {},
   "source": [
    "## 3. Limpieza de Datos\n",
    "\n",
    "Se redujo la cantidad de proveedores de 175278 a 155680 lo que nos da un total de 19598 proveedores menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be38b7-50e3-4550-a7fa-4e4c2d483726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas donde 'NombreProveedor' sea vacío (\"\"), guion (\"-\"), punto (\".\") o nulo (NaN)\n",
    "lic_all_years_clean = lic_all_years[~lic_all_years[\"NombreProveedor\"].isin([\"-\", \".\",\"---------\",\"- - -\",\" \",\"--\",\"0\",\"000000\",\"1\"]) \n",
    "                    & lic_all_years[\"NombreProveedor\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434db55-7171-493e-8172-b088362b9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_all_years_clean[\"NombreProveedor\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a60ca-6686-4df4-b6a7-561b32e4ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_all_years[\"NombreProveedor\"].nunique(),lic_all_years_clean[\"NombreProveedor\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar y estandarizar nombres\n",
    "def limpiar_nombre(nombre):\n",
    "    if pd.isna(nombre):  # Verifica si el valor es NaN\n",
    "        return np.nan\n",
    "    # Eliminar tildes\n",
    "    nombre = unicodedata.normalize('NFD', nombre).encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Convertir a minúsculas\n",
    "    nombre = nombre.lower()\n",
    "    # Eliminar caracteres no alfabéticos y no numéricos (excepto espacios)\n",
    "    nombre = re.sub(r'[^a-zA-Z0-9\\s]', '', nombre)\n",
    "    # Eliminar palabras como \"spa\", \"ltda\", etc.\n",
    "    nombre = re.sub(r'\\b(spa|ltda|sac|sa|sas|corp|inc|company|co|com|limit|limitada|limita|anónima)\\b', '', nombre)\n",
    "    # Eliminar múltiples espacios y dejar solo uno\n",
    "    nombre = re.sub(r'\\s+', ' ', nombre).strip()\n",
    "    return nombre\n",
    "\n",
    "\n",
    "# Crear una nueva columna para los nombres originales\n",
    "lic_all_years_clean['NombreProveedorOriginal'] = lic_all_years_clean['NombreProveedor']\n",
    "\n",
    "# Limpiar y crear la columna de nombres limpios\n",
    "lic_all_years_clean['NombreProveedorLimpio'] = lic_all_years_clean['NombreProveedor'].apply(limpiar_nombre)\n",
    "\n",
    "# Comparar nombres originales vs limpios\n",
    "comparacion_nombres = lic_all_years_clean[['NombreProveedorOriginal', 'NombreProveedorLimpio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6cb32-54a0-4d58-b16a-c1ee57f2492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas donde 'NombreProveedorLimpio' es vacío (\"\") después de la limpieza\n",
    "lic_all_years_clean = lic_all_years_clean[lic_all_years_clean['NombreProveedorLimpio'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16c9e3-a206-48f3-aaf1-b092fbd435e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el cambio, mostrando los primeros registros\n",
    "lic_all_years_clean[\"NombreProveedorLimpio\"].isna().sum(),lic_all_years_clean[\"NombreProveedorLimpio\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6fb6f-ce04-447a-8d0b-ef60c0016567",
   "metadata": {},
   "source": [
    "### 3.1 Filtrar datos del 2014-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7393f5-0947-479e-aa40-4eda7dd88a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar la data por los años 2014 a 2018\n",
    "lic_all_years_clean_2014_2018 = lic_all_years_clean[(lic_all_years_clean['Año'] >= 2014) & (lic_all_years_clean['Año'] <= 2018)]\n",
    "lic_all_years_clean_2019_2023 = lic_all_years_clean[(lic_all_years_clean['Año'] >= 2019) & (lic_all_years_clean['Año'] <= 2023)]\n",
    "\n",
    "# Mostrar los primeros registros del DataFrame filtrado\n",
    "lic_all_years_clean_2019_2023[\"Año\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47866d15",
   "metadata": {},
   "source": [
    "## 4. Cálculo VCR\n",
    "- No elimines duplicados indiscriminadamente: Cada registro puede representar una participación válida y única.\n",
    "- Asegúrate de que los datos reflejen la realidad de las participaciones: Esto garantizará que el VCR y otras métricas sean precisas.\n",
    "- Adapta tu análisis a la naturaleza de tus datos: Considera todas las variables relevantes para tu contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7751ed0-9c38-41cf-94c3-800eaf1c5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacion_col = 'Codigo'\n",
    "proveedor_col = 'NombreProveedorLimpio'\n",
    "rubro_col = 'RubroN2'\n",
    "producto_col = 'CodigoProductoONU'\n",
    "\n",
    "# Eliminar duplicados basados en licitación, proveedor, rubro y producto\n",
    "#lic_all_years_unique = lic_all_years_clean.drop_duplicates(subset=[licitacion_col, proveedor_col, rubro_col, producto_col])\n",
    "lic_all_years_unique_2014_2018 = lic_all_years_clean_2014_2018\n",
    "\n",
    "# Paso 1: Calcular el número total de participaciones en todos los rubros y proveedores\n",
    "participaciones_totales = len(lic_all_years_unique_2014_2018)\n",
    "\n",
    "# Paso 2: Calcular las participaciones únicas de cada proveedor en cada rubro\n",
    "participaciones_proveedor_rubro = lic_all_years_unique_2014_2018.groupby([proveedor_col, rubro_col]).size()\n",
    "\n",
    "# Paso 3: Calcular las participaciones totales por proveedor\n",
    "participaciones_totales_proveedor = lic_all_years_unique_2014_2018[proveedor_col].value_counts()\n",
    "\n",
    "# Paso 4: Calcular las participaciones totales por rubro\n",
    "participaciones_totales_rubro = lic_all_years_unique_2014_2018[rubro_col].value_counts()\n",
    "\n",
    "# Combinar los cálculos en un único DataFrame\n",
    "vcr_df = participaciones_proveedor_rubro.reset_index(name='participaciones_proveedor_rubro')\n",
    "vcr_df['participaciones_totales_proveedor'] = vcr_df[proveedor_col].map(participaciones_totales_proveedor)\n",
    "vcr_df['participaciones_totales_rubro'] = vcr_df[rubro_col].map(participaciones_totales_rubro)\n",
    "\n",
    "# Calcular el VCR utilizando la fórmula vectorizada\n",
    "vcr_df['VCR'] = (vcr_df['participaciones_proveedor_rubro'] / vcr_df['participaciones_totales_proveedor']) / \\\n",
    "                (vcr_df['participaciones_totales_rubro'] / participaciones_totales)\n",
    "\n",
    "# Filtrar proveedores con VCR >= 1 para indicar ventaja comparativa\n",
    "vcr_df['ventaja_comparativa'] = vcr_df['VCR']>=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21863f7-13a9-46fc-bd10-d9bca384f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_df[\"ventaja_comparativa\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ce29f-fe0c-438d-bf13-3ab579b4e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052119fa",
   "metadata": {},
   "source": [
    "## 5. Calculo de Matriz Especialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076bf2e-1d01-4640-90a8-740672e05db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Filtrar los proveedores con ventaja comparativa\n",
    "especializacion_df = vcr_df[vcr_df['ventaja_comparativa']][[proveedor_col, rubro_col]]\n",
    "\n",
    "# Paso 2: Crear índices para proveedores y rubros\n",
    "proveedores = especializacion_df[proveedor_col].unique()\n",
    "rubros = especializacion_df[rubro_col].unique()\n",
    "\n",
    "proveedor_idx = {proveedor: idx for idx, proveedor in enumerate(proveedores)}\n",
    "rubro_idx = {rubro: idx for idx, rubro in enumerate(rubros)}\n",
    "\n",
    "# Mapear los nombres a índices\n",
    "especializacion_df['proveedor_idx'] = especializacion_df[proveedor_col].map(proveedor_idx)\n",
    "especializacion_df['rubro_idx'] = especializacion_df[rubro_col].map(rubro_idx)\n",
    "\n",
    "# Verificar que no hay valores NaN en los índices\n",
    "assert not especializacion_df['proveedor_idx'].isnull().any(), \"Hay proveedores sin índice.\"\n",
    "assert not especializacion_df['rubro_idx'].isnull().any(), \"Hay rubros sin índice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb162e-5cd8-4309-8b04-bf12eb73b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que los índices son enteros\n",
    "especializacion_df['proveedor_idx'] = especializacion_df['proveedor_idx'].astype(int)\n",
    "especializacion_df['rubro_idx'] = especializacion_df['rubro_idx'].astype(int)\n",
    "\n",
    "# Paso 3: Construir la matriz de especialización dispersa\n",
    "data = np.ones(len(especializacion_df), dtype=np.int32)  # Cambiado a np.int32\n",
    "rows = especializacion_df['rubro_idx'].values\n",
    "cols = especializacion_df['proveedor_idx'].values\n",
    "\n",
    "matriz_especializacion_sparse = csr_matrix((data, (rows, cols)), shape=(len(rubros), len(proveedores)))\n",
    "\n",
    "# Verificar si hay valores negativos en matriz_especializacion_sparse\n",
    "if (matriz_especializacion_sparse.data < 0).any():\n",
    "    print(\"Advertencia: Se encontraron valores negativos en matriz_especializacion_sparse\")\n",
    "\n",
    "# Paso 4: Calcular el producto matricial disperso\n",
    "producto_sparse = matriz_especializacion_sparse @ matriz_especializacion_sparse.T\n",
    "\n",
    "# Verificar si hay valores negativos en producto_sparse\n",
    "if (producto_sparse.data < 0).any():\n",
    "    print(\"Advertencia: Se encontraron valores negativos en producto_sparse\")\n",
    "\n",
    "# Paso 5: Calcular la suma de proveedores por rubro\n",
    "suma_por_rubro = np.array(matriz_especializacion_sparse.sum(axis=1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a5900",
   "metadata": {},
   "source": [
    "## 6. Cálculo de Proximdiad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e07d2-c6b0-4296-85c6-c6a459191dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6: Calcular la matriz de proximidad\n",
    "producto_coo = producto_sparse.tocoo()\n",
    "\n",
    "max_sumas = np.maximum(suma_por_rubro[producto_coo.row], suma_por_rubro[producto_coo.col])\n",
    "\n",
    "# Evitar divisiones por cero\n",
    "max_sumas[max_sumas == 0] = np.finfo(float).eps\n",
    "\n",
    "# Calcular la proximidad\n",
    "proximidad_data = producto_coo.data / max_sumas\n",
    "\n",
    "# Verificar si hay valores negativos en proximidad_data\n",
    "if (proximidad_data < 0).any():\n",
    "    print(\"Advertencia: Se encontraron valores negativos en proximidad_data\")\n",
    "\n",
    "# Crear la matriz dispersa de proximidad\n",
    "proximidad_sparse = coo_matrix((proximidad_data, (producto_coo.row, producto_coo.col)), shape=producto_sparse.shape)\n",
    "\n",
    "# Opcional: Convertir a DataFrame si es manejable en memoria\n",
    "idx_to_rubro = {idx: rubro for rubro, idx in rubro_idx.items()}\n",
    "rubro_labels = [idx_to_rubro[idx] for idx in range(len(rubros))]\n",
    "\n",
    "proximidad_df = pd.DataFrame.sparse.from_spmatrix(proximidad_sparse, index=rubro_labels, columns=rubro_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d409432-f24a-488a-b6ef-2465e583b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proximidad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "proximidad_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9c7f3-0e41-4bef-86ea-0cda9f36ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Valor mínimo de proximidad: {proximidad_data.min()}\")\n",
    "print(f\"Valor máximo de proximidad: {proximidad_data.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04407a9-4687-4359-b54d-171c40e1a0f0",
   "metadata": {},
   "source": [
    "## 7. Red de Rubros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e5a2d-01dd-4fcf-9968-dcbd486920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un grafo desde la matriz de proximidad\n",
    "G = nx.from_pandas_adjacency(proximidad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51143b8-6b39-4ab8-bf00-123eea62fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G,\"GrafoProximidadRubros.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cd2e0-6c47-4f52-81e2-4debb72a7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información básica del grafo\n",
    "print(f\"Grafo creado con {G.number_of_nodes()} nodos y {G.number_of_edges()} aristas.\")\n",
    "\n",
    "# Opcional: Guardar el grafo en un archivo para visualización (formato GraphML o GEXF)\n",
    "nx.write_gexf(G, \"grafo_proximidad.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd1c65-7b3e-42eb-beab-775460600981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar las métricas\n",
    "metrics = {}\n",
    "\n",
    "# Métricas básicas\n",
    "metrics['weighted_degree'] = dict(G.degree(weight='weight'))  # Grado ponderado\n",
    "metrics['betweenness_centrality'] = nx.betweenness_centrality(G, weight='weight')  # Centralidad de intermediación\n",
    "metrics['closeness_centrality'] = nx.closeness_centrality(G)  # Centralidad de cercanía\n",
    "metrics['pagerank'] = nx.pagerank(G, weight='weight')  # PageRank\n",
    "metrics['clustering_coefficient'] = nx.clustering(G, weight='weight')  # Coeficiente de agrupamiento\n",
    "\n",
    "# Crear un DataFrame con todas las métricas\n",
    "metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c46fc-b885-464f-810c-15f6ce94c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetear el índice para incluir los nodos como una columna\n",
    "metrics_df.reset_index(inplace=True)\n",
    "\n",
    "# Renombrar la columna del índice como \"Rubro\"\n",
    "metrics_df.rename(columns={'index': 'Rubro'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5d439-3ec8-4451-9ce7-08a932848e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del DataFrame\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44160219",
   "metadata": {},
   "source": [
    "## 8. Cálculo de Density Relatedness \n",
    "Para cada proveedor y rubro no especializado, calcularemos la density relatedness como el promedio ponderado de la proximidad a los rubros en los que el proveedor ya está especializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00e42e-02a4-49f6-a05d-3fb3ae4929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar matrices y diccionarios\n",
    "matriz_especializacion_csr = matriz_especializacion_sparse.tocsr()\n",
    "proximidad_csr = proximidad_sparse.tocsr()\n",
    "todos_los_rubros = set(range(len(rubros)))\n",
    "idx_to_proveedor = {idx: proveedor for proveedor, idx in proveedor_idx.items()}\n",
    "idx_to_rubro = {idx: rubro for rubro, idx in rubro_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar listas para resultados\n",
    "lista_proveedores = []\n",
    "lista_rubros_potenciales = []\n",
    "lista_density_relatedness = []\n",
    "\n",
    "# Obtener la diagonal completa de proximidad_csr una sola vez\n",
    "diagonal_proximidad = proximidad_csr.diagonal()\n",
    "\n",
    "# Calcular el portafolio de cada proveedor y la density relatedness\n",
    "for proveedor_idx_actual in range(matriz_especializacion_csr.shape[1]):\n",
    "    rubros_con_ventaja = matriz_especializacion_csr[:, proveedor_idx_actual].nonzero()[0]\n",
    "    rubros_con_ventaja_set = set(rubros_con_ventaja)\n",
    "    rubros_potenciales = np.array(list(todos_los_rubros - rubros_con_ventaja_set))\n",
    "    if rubros_potenciales.size == 0:\n",
    "        continue\n",
    "\n",
    "    # Obtener las proximidades con el portafolio del proveedor\n",
    "    proximidades_con_portafolio = proximidad_csr[rubros_potenciales[:, None], rubros_con_ventaja].toarray()\n",
    "\n",
    "    # Sumar las proximidades con el portafolio para cada rubro potencial\n",
    "    suma_proximidades_portafolio = proximidades_con_portafolio.sum(axis=1)\n",
    "\n",
    "    # Obtener las proximidades totales del rubro potencial\n",
    "    proximidades_totales = proximidad_csr[rubros_potenciales].toarray()\n",
    "\n",
    "    # Sumar todas las proximidades excepto la del rubro consigo mismo (diagonal)\n",
    "    diagonales_rubros_potenciales = diagonal_proximidad[rubros_potenciales]\n",
    "    suma_proximidades_totales = proximidades_totales.sum(axis=1) - diagonales_rubros_potenciales\n",
    "\n",
    "    # Evitar divisiones por cero\n",
    "    suma_proximidades_totales[suma_proximidades_totales == 0] = np.finfo(float).eps\n",
    "\n",
    "    # Calcular la Density Relatedness\n",
    "    density = suma_proximidades_portafolio / suma_proximidades_totales\n",
    "\n",
    "    # Almacenar los resultados\n",
    "    proveedores_repetidos = [idx_to_proveedor[proveedor_idx_actual]] * len(rubros_potenciales)\n",
    "    rubros_potenciales_nombres = [idx_to_rubro[idx] for idx in rubros_potenciales]\n",
    "    lista_proveedores.extend(proveedores_repetidos)\n",
    "    lista_rubros_potenciales.extend(rubros_potenciales_nombres)\n",
    "    lista_density_relatedness.extend(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43ee3e-05ef-4bd6-af62-7c55cc4afa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame final\n",
    "density_df = pd.DataFrame({\n",
    "    'NombreProveedorLimpio': lista_proveedores,\n",
    "    'RubroPotencial': lista_rubros_potenciales,\n",
    "    'DensityRelatedness': lista_density_relatedness\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e09e6-08fa-491e-9c23-fb26bdd5139a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "density_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb852f-8eb4-414f-a784-286c7ee412ce",
   "metadata": {},
   "source": [
    "## 9. Enriquecer Caracteristicas del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe6d51-f37c-4568-b049-1b4c5c37f4d0",
   "metadata": {},
   "source": [
    "### 9.1 Caracteristicas Proveedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693efd9-b77a-41eb-a3eb-df093da3896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'lic_all_years_clean' es tu DataFrame original\n",
    "# Primero, creamos una copia del DataFrame para trabajar con ella\n",
    "df = lic_all_years_clean_2014_2018.copy()\n",
    "\n",
    "# Filtrar los montos adjudicados\n",
    "df['MontoTotalAdjudicado'] = df['MontoLineaAdjudica'].where((df['MontoLineaAdjudica'] >= 1) & (df['MontoLineaAdjudica'] <= 10**12))\n",
    "\n",
    "# Crear una columna que indique si la oferta fue seleccionada\n",
    "df['Adjudicada'] = df['Oferta seleccionada'] == 'Seleccionada'\n",
    "\n",
    "# Total adjudicaciones proveedor (solo las adjudicadas)\n",
    "df['TotalAdjudicacionesProveedor'] = df.groupby('NombreProveedorLimpio')['Adjudicada'].transform('sum')\n",
    "\n",
    "# Total participaciones proveedor\n",
    "df['TotalParticipacionesProveedor'] = df.groupby('NombreProveedorLimpio')['Codigo'].transform('size')\n",
    "\n",
    "# % Adjudicación proveedor\n",
    "df['%AdjudicacionProveedor'] = (df['TotalAdjudicacionesProveedor'] / df['TotalParticipacionesProveedor']) * 100\n",
    "\n",
    "# Total Monto adjudicado proveedor (filtrado)\n",
    "df['TotalMontoAdjudicadoProveedor'] = df.groupby('NombreProveedorLimpio')['MontoTotalAdjudicado'].transform('sum')\n",
    "\n",
    "# Total Monto promedio adjudicado proveedor (filtrado)\n",
    "df['TotalMontoPromedioAdjudicadoProveedor'] = df.groupby('NombreProveedorLimpio')['MontoTotalAdjudicado'].transform('mean')\n",
    "\n",
    "# Numero de rubros con ventaja\n",
    "df['NumeroRubrosConVentaja'] = df.groupby('NombreProveedorLimpio')['RubroN2'].transform(lambda x: x.nunique())\n",
    "\n",
    "# Total monto adjudicado rubro (filtrado)\n",
    "df['TotalMontoAdjudicadoRubro'] = df.groupby('RubroN2')['MontoTotalAdjudicado'].transform('sum')\n",
    "\n",
    "# Total monto promedio adjudicado rubro (filtrado)\n",
    "df['TotalMontoPromedioAdjudicadoRubro'] = df.groupby('RubroN2')['MontoTotalAdjudicado'].transform('mean')\n",
    "\n",
    "# Numero de proveedores rubro\n",
    "df['NumeroProveedoresRubro'] = df.groupby('RubroN2')['NombreProveedorLimpio'].transform(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7211e-f60c-43de-a213-08d30236fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados en df para las claves de unión\n",
    "df_proveedor = df[['NombreProveedorLimpio', 'TotalAdjudicacionesProveedor', \n",
    "                   'TotalParticipacionesProveedor', '%AdjudicacionProveedor', \n",
    "                   'TotalMontoAdjudicadoProveedor', \n",
    "                   'TotalMontoPromedioAdjudicadoProveedor', \n",
    "                   'NumeroRubrosConVentaja']].drop_duplicates()\n",
    "\n",
    "df_rubro = df[['RubroN2', 'TotalMontoAdjudicadoRubro', \n",
    "                'TotalMontoPromedioAdjudicadoRubro', \n",
    "                'NumeroProveedoresRubro']].drop_duplicates()\n",
    "\n",
    "# Realizar el merge para las características del proveedor\n",
    "density_df = density_df.merge(df_proveedor, left_on='NombreProveedorLimpio', right_on='NombreProveedorLimpio', how='left')\n",
    "\n",
    "# Realizar el merge para las características del rubro\n",
    "density_df = density_df.merge(df_rubro, left_on='RubroPotencial', right_on='RubroN2', how='left')\n",
    "\n",
    "# Eliminar las columnas que ya existen en density_df\n",
    "columnas_a_eliminar = ['RubroN2']  # Agrega más columnas si es necesario\n",
    "density_df = density_df.loc[:, ~density_df.columns.isin(columnas_a_eliminar)]\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "density_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d738222-c512-48de-9363-1295af7a26f6",
   "metadata": {},
   "source": [
    "### 9.2 Unir con metricas de Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de40293-e2fb-4506-be91-60500bcba50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7732332-5f23-4171-b217-d920920d7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge para las características del rubro\n",
    "density_df = density_df.merge(metrics_df, left_on='RubroPotencial', right_on='Rubro', how='left')\n",
    "\n",
    "# Eliminar las columnas que ya existen en density_df\n",
    "columnas_a_eliminar_red = ['Rubro']  # Agrega más columnas si es necesario\n",
    "density_df = density_df.loc[:, ~density_df.columns.isin(columnas_a_eliminar_red)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f32e8-a3db-45b1-8ecb-83e15dd3cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed502a6e-5a47-48c9-95d4-8f0e15347d91",
   "metadata": {},
   "source": [
    "## 10. Cargar y preprocesar datos de 2019 al 2023 [Generar Etiqueta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2270e9-142d-4682-8e01-ab8987a5e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_all_years_clean_2019_2023[\"Año\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee01e8-258e-464f-aa9a-22c66d80aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Calcular el número total de participaciones en 2019-2023\n",
    "participaciones_totales_2019_2023 = len(lic_all_years_clean_2019_2023)\n",
    "\n",
    "# Paso 2: Calcular las participaciones únicas de cada proveedor en cada rubro\n",
    "participaciones_proveedor_rubro_2019_2023 = lic_all_years_clean_2019_2023.groupby([proveedor_col, rubro_col]).size()\n",
    "\n",
    "# Paso 3: Calcular las participaciones totales por proveedor\n",
    "participaciones_totales_proveedor_2019_2023 = lic_all_years_clean_2019_2023[proveedor_col].value_counts()\n",
    "\n",
    "# Paso 4: Calcular las participaciones totales por rubro\n",
    "participaciones_totales_rubro_2019_2023 = lic_all_years_clean_2019_2023[rubro_col].value_counts()\n",
    "\n",
    "# Combinar los cálculos en un DataFrame\n",
    "vcr_df_2019_2023 = participaciones_proveedor_rubro_2019_2023.reset_index(name='participaciones_proveedor_rubro')\n",
    "vcr_df_2019_2023['participaciones_totales_proveedor'] = vcr_df_2019_2023[proveedor_col].map(participaciones_totales_proveedor_2019_2023)\n",
    "vcr_df_2019_2023['participaciones_totales_rubro'] = vcr_df_2019_2023[rubro_col].map(participaciones_totales_rubro_2019_2023)\n",
    "\n",
    "# Calcular el VCR\n",
    "vcr_df_2019_2023['VCR'] = (vcr_df_2019_2023['participaciones_proveedor_rubro'] / vcr_df_2019_2023['participaciones_totales_proveedor']) / \\\n",
    "                           (vcr_df_2019_2023['participaciones_totales_rubro'] / participaciones_totales_2019_2023)\n",
    "\n",
    "# Determinar si tiene ventaja comparativa\n",
    "vcr_df_2019_2023['ventaja_comparativa'] = vcr_df_2019_2023['VCR'] >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839f3ef-935e-43a5-bb4c-8de7bd1e8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_df_2019_2023[\"ventaja_comparativa\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5794e-a3e2-4b20-bda8-487a0e1fe1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_2019_2023_exito = vcr_df_2019_2023[vcr_df_2019_2023['ventaja_comparativa']][[proveedor_col, rubro_col]].copy()\n",
    "vcr_2019_2023_exito['Exito'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15172c4-4afe-4b8c-b1af-d1fcb3063642",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_2019_2023_exito.rename(columns={\"RubroN2\":\"RubroPotencial\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d470786-513f-4aaf-b9b3-a9ae0f031305",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcr_2019_2023_exito.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a0b9c-06dc-42d0-b31b-3e6619a3af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge\n",
    "density_df = density_df.merge(vcr_2019_2023_exito[['NombreProveedorLimpio', 'RubroPotencial','Exito']],\n",
    "                              left_on=['NombreProveedorLimpio', 'RubroPotencial'],\n",
    "                              right_on=['NombreProveedorLimpio', 'RubroPotencial'],\n",
    "                              how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805864df-1ee7-4f7a-94e1-a695983d8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3568c-1882-4e3d-98f2-a4327c0c071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN en 'Exito' por 0 (proveedores que no obtuvieron ventaja comparativa en el rubro potencial)\n",
    "density_df['Exito'] = density_df['Exito'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdc9c5-9c48-4074-b080-e145acd2ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de la etiqueta\n",
    "print(density_df['Exito'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c63a6a-cd65-4038-8161-332842c29f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4375965-5730-4918-a7f0-8e71f4062d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c25b6e-227c-4475-ae4f-da050c6aabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_df.to_parquet(\"density_data.parquet\", engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af34bc-362b-4498-8aa6-d0075127774a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Para leer el archivo Parquet que guardaste anteriormente\n",
    "density_df = pd.read_parquet(\"density_data.parquet\")\n",
    "density_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b13c60-8f75-457b-ae07-d9f21968a08c",
   "metadata": {},
   "source": [
    "## 11. Definir las Características (Variables Predictoras) y la Etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a25c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \"\"\"Reduce el uso de memoria de un DataFrame.\"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:  # Excluir columnas categóricas\n",
    "            if str(col_type).startswith('int'):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            elif str(col_type).startswith('float'):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "# Reducir el uso de memoria\n",
    "density_df = reduce_memory_usage(density_df)\n",
    "\n",
    "# Verificar la reducción de memoria\n",
    "print(density_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33249448-82d8-4984-a502-effbf5ab3e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, average_precision_score, confusion_matrix)\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = density_df.drop(['RubroPotencial', 'NombreProveedorLimpio', 'Exito'], axis=1)\n",
    "y = density_df['Exito']\n",
    "\n",
    "# Escalar las variables predictoras\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir X_scaled nuevamente a un DataFrame con los nombres originales\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Reemplazar valores NaN por 0\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b8fb6-063b-4e9c-8b48-fe298d07edda",
   "metadata": {},
   "source": [
    "## 12. Implementar Modelo XGboost con proporción 7 veces mas de clase mayoritaria y evaluar en la distribución real de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39a5d5-726c-4680-9747-449dc8b68265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train_original, X_test, y_train_original, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32c886-be09-4a82-a041-54d4f2fdee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, average_precision_score, confusion_matrix, \n",
    "                             roc_curve, precision_recall_curve)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Crear un conjunto balanceado (Proporción 7)\n",
    "data_train = X_train_original.copy()\n",
    "data_train['Exito'] = y_train_original\n",
    "\n",
    "# Separar las clases\n",
    "data_majority = data_train[data_train['Exito'] == 0]\n",
    "data_minority = data_train[data_train['Exito'] == 1]\n",
    "\n",
    "# Submuestrear la clase mayoritaria\n",
    "proportion = 7\n",
    "data_majority_downsampled = resample(\n",
    "    data_majority,\n",
    "    replace=False,  # Sin reemplazo\n",
    "    n_samples=len(data_minority) * proportion,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinar las clases balanceadas\n",
    "data_balanced = pd.concat([data_majority_downsampled, data_minority])\n",
    "\n",
    "# Separar las variables predictoras (X) y la etiqueta (y)\n",
    "X_train = data_balanced.drop('Exito', axis=1)\n",
    "y_train = data_balanced['Exito']\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "# Obtener la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Exito', 'Exito'], yticklabels=['No Exito', 'Exito'])\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Valores Reales')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC-ROC = {auc_roc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Curva PR\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_vals, precision_vals, label=f\"AUC-PR = {auc_pr:.4f}\")\n",
    "plt.title('Curva de Precisión-Recall')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Obtener la importancia de las variables\n",
    "importance = model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Garantizar que todas las variables se incluyan, incluso las que no fueron usadas (importancia 0)\n",
    "all_features = X_train.columns.tolist()\n",
    "importance_full = {feature: importance.get(feature, 0) for feature in all_features}\n",
    "\n",
    "# Convertir a DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance_full.keys()),\n",
    "    'F_Score': list(importance_full.values())\n",
    "})\n",
    "importance_df['Percentage'] = (importance_df['F_Score'] / importance_df['F_Score'].sum()) * 100\n",
    "importance_df = importance_df.sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "# Mostrar resultados\n",
    "def print_results():\n",
    "    print(\"\\n### Resultados del Modelo ###\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "    print(\"\\n### Importancia de Variables (Todas) ###\")\n",
    "    print(importance_df)\n",
    "\n",
    "# Visualización opcional de todas las variables con colores diferenciados\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Asignar colores: 'red' para \"density relatedness\" y 'skyblue' para las demás\n",
    "colors = ['red' if feature == 'density relatedness' else 'skyblue' for feature in importance_df['Feature']]\n",
    "\n",
    "plt.barh(importance_df['Feature'], importance_df['Percentage'], color=colors)\n",
    "plt.xlabel('Porcentaje de Importancia')\n",
    "plt.ylabel('Variable')\n",
    "plt.title('Importancia de Todas las Variables')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Call to display results\n",
    "print_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086f50e-0bf7-4956-8d82-5e94ba14f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar colores: rojo para \"density relatedness\" y gris para las demás\n",
    "colors = ['red' if feature == 'DensityRelatedness' else 'lightgray' for feature in importance_df['Feature']]\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Percentage'], color=colors, edgecolor='none')\n",
    "\n",
    "# Configuración del gráfico\n",
    "plt.xlabel('Porcentaje de Importancia', fontsize=14)\n",
    "plt.ylabel('Variable', fontsize=14)\n",
    "plt.title('Importancia de Variables (Destacando density relatedness)', fontsize=16)\n",
    "plt.gca().invert_yaxis()  # Invertir el eje y para que las variables con mayor importancia estén arriba\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30d871-1c09-4ea6-8883-b2b9ec2a95d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 12.1 Análisis de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3aeb9-210b-4641-a979-2f47b7991479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables predictoras completas\n",
    "features = [\n",
    "    'TotalMontoAdjudicadoProveedor', 'DensityRelatedness',\n",
    "    'TotalMontoPromedioAdjudicadoProveedor', 'NumeroRubrosConVentaja',\n",
    "    'TotalParticipacionesProveedor', '%AdjudicacionProveedor',\n",
    "    'NumeroProveedoresRubro', 'TotalAdjudicacionesProveedor',\n",
    "    'TotalMontoAdjudicadoRubro', 'TotalMontoPromedioAdjudicadoRubro',\n",
    "    'weighted_degree', 'clustering_coefficient','betweenness_centrality', \n",
    "    'pagerank', 'closeness_centrality']\n",
    "\n",
    "\n",
    "# Matriz de correlación\n",
    "correlation_matrix = X_train_original[features].corr()\n",
    "\n",
    "# Visualizar matriz de correlación\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Matriz de Correlación de Variables Predictoras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9cfdbf-d016-4612-b610-d613b3d37576",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 12.2 Analisis Multicolinealidad\n",
    "\n",
    "Eliminar las variables con VIF extremadamente alto como:\n",
    "\n",
    "- weighted_degree (282.01)\n",
    "- clustering_coefficient (42.09)\n",
    "- pagerank (207.85)\n",
    "- eigenvector_centrality (32.83)\n",
    "\n",
    "Estas variables presentan una alta multicolinealidad, lo que significa que están explicando información que ya está capturada por otras variables en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae880ef-3b9d-4393-a585-7f2d48bac9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "\n",
    "# Crear un DataFrame con las variables predictoras\n",
    "X_vif = X_train_original[features]\n",
    "\n",
    "# Calcular VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "\n",
    "print(\"\\n### VIF de las Variables Predictoras ###\")\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3088968-e34e-4569-9b24-dcab3d53487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544a305-0576-42a1-b024-1c23d6145158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la clase StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Variables predictoras (excluyendo 'RubroPotencial', 'NombreProveedorLimpio', 'Exito', etc.)\n",
    "X = density_df.drop(['RubroPotencial', 'NombreProveedorLimpio', 'Exito','pagerank'], axis=1)\n",
    "\n",
    "# Crear un escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar X\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir X_scaled de nuevo a un DataFrame y asignar los nombres de las columnas\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Etiqueta (variable objetivo)\n",
    "y = density_df['Exito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Dividir los datos originales en entrenamiento y prueba (proporción original)\n",
    "X_train_original, X_test, y_train_original, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bfcf7-6708-4646-b905-30b68b9ca78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Definir los datos originales (asegúrate de que `X_train_original` y `y_train_original` estén definidos)\n",
    "data_train = X_train_original.copy()\n",
    "data_train['Exito'] = y_train_original\n",
    "\n",
    "# Separar las clases\n",
    "data_majority = data_train[data_train['Exito'] == 0]\n",
    "data_minority = data_train[data_train['Exito'] == 1]\n",
    "\n",
    "# Proporción específica: 7\n",
    "proportion = 7\n",
    "\n",
    "# Submuestrear la clase mayoritaria\n",
    "data_majority_downsampled = resample(\n",
    "    data_majority,\n",
    "    replace=False,  # Sin reemplazo\n",
    "    n_samples=len(data_minority) * proportion,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinar la clase minoritaria con la clase mayoritaria submuestreada\n",
    "data_balanced = pd.concat([data_majority_downsampled, data_minority])\n",
    "\n",
    "# Separar X y y en el conjunto balanceado\n",
    "X_train = data_balanced.drop('Exito', axis=1)\n",
    "y_train = data_balanced['Exito']\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas principales\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular AUC-ROC y AUC-PR\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "# Guardar la importancia de las variables\n",
    "importance = model.get_booster().get_score(importance_type='weight')\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance.keys()),\n",
    "    'F_Score': list(importance.values())\n",
    "})\n",
    "importance_df['Percentage'] = (importance_df['F_Score'] / importance_df['F_Score'].sum()) * 100\n",
    "importance_df = importance_df.sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\n### Resultados del Modelo 5 (Proporción 7) ###\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Opcional: Guardar los resultados en un archivo CSV\n",
    "#importance_df.to_csv(\"feature_importance_proportion_7.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8676c-26b3-4e1b-a502-1e863c7cf021",
   "metadata": {},
   "outputs": [],
   "source": [
    "c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc109a-50db-4fe0-8b45-cc75c3d7a333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7dd13-88ec-4d98-a8c0-680406a2557d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ddc12a-9894-471a-89ff-6d609f59f767",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8526d194",
   "metadata": {},
   "source": [
    "## 14. Densi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Asegúrate de que la columna 'DensityRelatedness' y 'Exito' sean numéricas\n",
    "density_df['DensityRelatedness'] = pd.to_numeric(density_df['DensityRelatedness'], errors='coerce')\n",
    "density_df['Exito'] = pd.to_numeric(density_df['Exito'], errors='coerce')\n",
    "\n",
    "# Dividir los valores de Density Relatedness en bins\n",
    "bins = np.linspace(0, 1, 11)  # Dividir de 0 a 1 en 10 intervalos iguales\n",
    "density_df['Density_Bin'] = pd.cut(density_df['DensityRelatedness'], bins=bins)\n",
    "\n",
    "# Calcular la probabilidad promedio de éxito por bin y el error estándar\n",
    "bin_means = density_df.groupby('Density_Bin')['Exito'].mean()\n",
    "bin_errors = density_df.groupby('Density_Bin')['Exito'].sem()  # Error estándar de la media\n",
    "\n",
    "# Etiquetas de los bins\n",
    "bin_labels = [f'{round(b.left, 2)} - {round(b.right, 2)}' for b in bin_means.index]\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_labels, bin_means, yerr=bin_errors, alpha=0.7, capsize=5, color='skyblue')\n",
    "plt.xlabel('Density Relatedness (ωpr)')\n",
    "plt.ylabel('Probabilidad de desarrollar VCR en 5 años')\n",
    "plt.title('Probabilidad de desarrollar VCR por Density Relatedness')\n",
    "plt.xticks(rotation=45)  # Rotar etiquetas para mejor visibilidad\n",
    "plt.tight_layout()  # Ajustar los márgenes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4dc237",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 15. Análisis del MontoAdjudicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73db5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar tipos de datos\n",
    "lic_all_years_clean_2014_2018['MontoLineaAdjudica'] = lic_all_years_clean_2014_2018['MontoLineaAdjudica'].astype(np.float32)\n",
    "mapeo_oferta = {\n",
    "    'Seleccionada': 'Seleccionada',\n",
    "    'No Seleccionada': 'No Seleccionada',\n",
    "    'No sleccionada': 'No Seleccionada',\n",
    "    'Perdedora': 'No Seleccionada'\n",
    "}\n",
    "lic_all_years_clean_2014_2018['Oferta seleccionada'] = lic_all_years_clean_2014_2018['Oferta seleccionada'].replace(mapeo_oferta)\n",
    "# Mapear a valores numéricos para cálculos\n",
    "lic_all_years_clean_2014_2018['Oferta seleccionada'] = lic_all_years_clean_2014_2018['Oferta seleccionada'].map({'Seleccionada': 1, 'No Seleccionada': 0}).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica que 'Oferta seleccionada' exista, si no, créala\n",
    "if 'Oferta seleccionada' not in lic_all_years_clean_2014_2018.columns:\n",
    "    lic_all_years_clean_2014_2018['Oferta seleccionada'] = 'No seleccionada'\n",
    "\n",
    "# Modifica los valores según la condición\n",
    "lic_all_years_clean_2014_2018['Oferta seleccionada'] = lic_all_years_clean_2014_2018['MontoLineaAdjudica'].apply(\n",
    "    lambda x: 'Seleccionada' if x > 0 else 'No seleccionada'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb46d2-56ad-4c3d-8ea8-06509fb7b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lic_all_years_clean_2014_2018['Oferta seleccionada'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4586ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar valores válidos (mayores a 1 y menores a 10**12)\n",
    "valid_data = lic_all_years_clean_2014_2018[\n",
    "    (lic_all_years_clean_2014_2018['MontoLineaAdjudica'] > 1) & \n",
    "    (lic_all_years_clean_2014_2018['MontoLineaAdjudica'] < 10**12)\n",
    "]\n",
    "\n",
    "# Verifica el resultado del filtrado\n",
    "print(f\"Número de registros después del filtrado: {len(valid_data)}\")\n",
    "print(\"Resumen estadístico de MontoLineaAdjudica (post-filtrado):\")\n",
    "print(valid_data['MontoLineaAdjudica'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa54673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización inicial de la distribución\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(valid_data['MontoLineaAdjudica'], bins=50, edgecolor='black')\n",
    "plt.title('Distribución inicial de MontoLineaAdjudica (valores válidos)')\n",
    "plt.xlabel('Monto')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.yscale('log')  # Escala logarítmica para exponer valores más altos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803ac26-5825-45f9-8af3-77a94a8a6308",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 16. Visualizando un caso de éxito "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faad4f3-9c14-43be-ad96-09cfcac5e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Filtrar portafolio actual (rubros con VCR > 1)\n",
    "    proveedor = \"soloverde\"\n",
    "    portafolio_actual = vcr_df[(vcr_df['NombreProveedorLimpio'] == proveedor) & (vcr_df['VCR'] > 1)]\n",
    "\n",
    "    # Identificar rubros potenciales desde density_df\n",
    "    rubros_potenciales = density_df[density_df['NombreProveedorLimpio'] == proveedor]\n",
    "\n",
    "    # Seleccionar 2 rubros exitosos y 2 no exitosos\n",
    "    rubros_exitosos = rubros_potenciales[rubros_potenciales['Exito'] == True].head(2)\n",
    "    rubros_no_exitosos = rubros_potenciales[rubros_potenciales['Exito'] == False].head(2)\n",
    "\n",
    "    # Combinar todos los nodos (actuales y potenciales)\n",
    "    nodos_actuales = portafolio_actual['RubroN2'].tolist()\n",
    "    nodos_exitosos = rubros_exitosos['RubroPotencial'].tolist()\n",
    "    nodos_no_exitosos = rubros_no_exitosos['RubroPotencial'].tolist()\n",
    "    todos_nodos = nodos_actuales + nodos_exitosos + nodos_no_exitosos\n",
    "\n",
    "    # Crear el grafo desde proximidad_df filtrando nodos relevantes\n",
    "    G = nx.Graph()\n",
    "    for nodo in todos_nodos:\n",
    "        G.add_node(nodo, tipo='actual' if nodo in nodos_actuales else 'exitoso' if nodo in nodos_exitosos else 'no_exitoso')\n",
    "\n",
    "    for i, nodo1 in enumerate(todos_nodos):\n",
    "        for nodo2 in todos_nodos[i + 1:]:\n",
    "            if nodo1 in proximidad_df.index and nodo2 in proximidad_df.columns:\n",
    "                peso = proximidad_df.loc[nodo1, nodo2]\n",
    "                if peso > 0:  # Filtrar solo conexiones relevantes\n",
    "                    G.add_edge(nodo1, nodo2, weight=peso)\n",
    "\n",
    "    # Asignar colores mejorados a los nodos\n",
    "    color_map_actuales = '#1f78b4'  # Azul intenso\n",
    "    color_map_exitosos = '#33a02c'  # Verde esmeralda\n",
    "    color_map_no_exitosos = '#ff7f00'  # Naranja brillante\n",
    "    node_colors = [\n",
    "        color_map_actuales if G.nodes[n]['tipo'] == 'actual' \n",
    "        else color_map_exitosos if G.nodes[n]['tipo'] == 'exitoso' \n",
    "        else color_map_no_exitosos \n",
    "        for n in G.nodes\n",
    "    ]\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42, k=0.5)  # Ajustar posiciones\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='gray', node_size=800, font_size=9, alpha=0.9)\n",
    "\n",
    "    # Agregar leyenda\n",
    "    legend_labels = {\n",
    "        color_map_actuales: 'Rubros Actuales',\n",
    "        color_map_exitosos: 'Rubros Potenciales Exitosos',\n",
    "        color_map_no_exitosos: 'Rubros Potenciales No Exitosos'\n",
    "    }\n",
    "    for color, label in legend_labels.items():\n",
    "        plt.scatter([], [], color=color, label=label)\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.title(f'Portafolio y Rubros Potenciales del Proveedor: {proveedor}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
